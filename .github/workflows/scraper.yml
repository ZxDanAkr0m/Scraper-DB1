name: Goodreads Scrapers

on:
  schedule:
    - cron: "0 6 * * *"   # run every day at 06:00 UTC
  workflow_dispatch:       # allows manual run from GitHub

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install Chromium and ChromeDriver
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            xvfb \
            chromium-browser \
            chromium-chromedriver \
            libnss3 \
            libgconf-2-4 \
            libxi6 \
            libxcursor1 \
            libxcomposite1 \
            libasound2 \
            libxdamage1 \
            libxrandr2 \
            libatk1.0-0 \
            libatk-bridge2.0-0 \
            libgbm1 \
            libxshmfence1

      - name: Run scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          GOODREADS_COOKIES: ${{ secrets.GOODREADS_COOKIES }}
        run: |
          xvfb-run -a python scrape.py
